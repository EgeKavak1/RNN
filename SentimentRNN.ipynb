{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d07263e8-7ecf-45c0-addc-f9592422bc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullanılan Cihaz: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "\n",
    "# GPU varsa kullan, yoksa CPU kullan\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Kullanılan Cihaz: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec9000b-110e-4dde-8a4e-ad02f75405b3",
   "metadata": {},
   "source": [
    "## VERİ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71cc556e-25bc-4305-8d7f-7202cea5a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {\n",
    "  'good': True,\n",
    "  'bad': False,\n",
    "  'happy': True,\n",
    "  'sad': False,\n",
    "  'not good': False,\n",
    "  'not bad': True,\n",
    "  'not happy': False,\n",
    "  'not sad': True,\n",
    "  'very good': True,\n",
    "  'very bad': False,\n",
    "  'very happy': True,\n",
    "  'very sad': False,\n",
    "  'i am happy': True,\n",
    "  'this is good': True,\n",
    "  'i am bad': False,\n",
    "  'this is bad': False,\n",
    "  'i am sad': False,\n",
    "  'this is sad': False,\n",
    "  'i am not happy': False,\n",
    "  'this is not good': False,\n",
    "  'i am not bad': True,\n",
    "  'this is not sad': True,\n",
    "  'i am very happy': True,\n",
    "  'this is very good': True,\n",
    "  'i am very bad': False,\n",
    "  'this is very sad': False,\n",
    "  'this is very happy': True,\n",
    "  'i am good not bad': True,\n",
    "  'this is good not bad': True,\n",
    "  'i am bad not good': False,\n",
    "  'i am good and happy': True,\n",
    "  'this is not good and not happy': False,\n",
    "  'i am not at all good': False,\n",
    "  'i am not at all bad': True,\n",
    "  'i am not at all happy': False,\n",
    "  'this is not at all sad': True,\n",
    "  'this is not at all happy': False,\n",
    "  'i am good right now': True,\n",
    "  'i am bad right now': False,\n",
    "  'this is bad right now': False,\n",
    "  'i am sad right now': False,\n",
    "  'i was good earlier': True,\n",
    "  'i was happy earlier': True,\n",
    "  'i was bad earlier': False,\n",
    "  'i was sad earlier': False,\n",
    "  'i am very bad right now': False,\n",
    "  'this is very good right now': True,\n",
    "  'this is very sad right now': False,\n",
    "  'this was bad earlier': False,\n",
    "  'this was very good earlier': True,\n",
    "  'this was very bad earlier': False,\n",
    "  'this was very happy earlier': True,\n",
    "  'this was very sad earlier': False,\n",
    "  'i was good and not bad earlier': True,\n",
    "  'i was not good and not happy earlier': False,\n",
    "  'i am not at all bad or sad right now': True,\n",
    "  'i am not at all good or happy right now': False,\n",
    "  'this was not happy and not good earlier': False,\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "  'this is happy': True,\n",
    "  'i am good': True,\n",
    "  'this is not happy': False,\n",
    "  'i am not good': False,\n",
    "  'this is not bad': True,\n",
    "  'i am not sad': True,\n",
    "  'i am very good': True,\n",
    "  'this is very bad': False,\n",
    "  'i am very sad': False,\n",
    "  'this is bad not good': False,\n",
    "  'this is good and happy': True,\n",
    "  'i am not good and not happy': False,\n",
    "  'i am not at all sad': True,\n",
    "  'this is not at all good': False,\n",
    "  'this is not at all bad': True,\n",
    "  'this is good right now': True,\n",
    "  'this is sad right now': False,\n",
    "  'this is very bad right now': False,\n",
    "  'this was good earlier': True,\n",
    "  'i was not happy and not good earlier': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87543d51-be66-4554-b582-ba33fc71fd96",
   "metadata": {},
   "source": [
    "## VERİ HAZIRLIĞI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cef2d214-dcce-408f-bef6-7daf7a604859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelime Haznesi Boyutu: 20\n",
      "Maksimum Dizi Uzunluğu: 10\n",
      "Eğitim Verisi Tensor Şekli: torch.Size([58, 10]), Etiket Şekli: torch.Size([58, 1])\n",
      "Test Verisi Tensor Şekli: torch.Size([20, 10]), Etiket Şekli: torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "def clean_and_tokenize(sentence):\n",
    "    # Basit temizleme ve tokenizasyon\n",
    "    sentence = re.sub(r'[^a-z ]', '', sentence.lower())\n",
    "    return sentence.split()\n",
    "\n",
    "def build_vocab(data, min_freq=1):\n",
    "    # Veri setindeki tüm kelimelerden kelime haznesi oluştur\n",
    "    all_tokens = []\n",
    "    for sentence in data.keys():\n",
    "        all_tokens.extend(clean_and_tokenize(sentence))\n",
    "\n",
    "    token_counts = collections.Counter(all_tokens)\n",
    "    # Belirli bir frekanstan az olan kelimeleri at\n",
    "    vocab = [token for token, count in token_counts.items() if count >= min_freq]\n",
    "\n",
    "    # Özel tokenlar ekle: <PAD> (doldurma) ve <UNK> (bilinmeyen)\n",
    "    vocab.insert(0, '<PAD>')\n",
    "    vocab.insert(1, '<UNK>')\n",
    "\n",
    "    word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "    idx_to_word = {i: word for word, i in word_to_idx.items()}\n",
    "\n",
    "    return word_to_idx, idx_to_word\n",
    "\n",
    "def sentence_to_indices(sentence, word_to_idx, max_len):\n",
    "    # Cümleyi temizle, tokenlara ayır ve indeks dizisine çevir\n",
    "    tokens = clean_and_tokenize(sentence)\n",
    "    indices = [word_to_idx.get(token, word_to_idx['<UNK>']) for token in tokens]\n",
    "\n",
    "    # Padding veya Truncation\n",
    "    if len(indices) < max_len:\n",
    "        # Padding (sona <PAD> indeksi ekle)\n",
    "        padding = [word_to_idx['<PAD>']] * (max_len - len(indices))\n",
    "        indices.extend(padding)\n",
    "    elif len(indices) > max_len:\n",
    "        # Truncation (baştan kes)\n",
    "        indices = indices[:max_len]\n",
    "\n",
    "    return indices\n",
    "\n",
    "def prepare_dataset(data, word_to_idx, max_len):\n",
    "    # Veri setini PyTorch tensorlarına dönüştür\n",
    "    all_indices = []\n",
    "    labels = []\n",
    "\n",
    "    for sentence, label in data.items():\n",
    "        indices = sentence_to_indices(sentence, word_to_idx, max_len)\n",
    "        all_indices.append(indices)\n",
    "        labels.append(float(label)) # PyTorch beklentisi float\n",
    "\n",
    "    # Numpy array'lere çevir ve sonra PyTorch tensorlarına\n",
    "    # Batch boyutu ilk boyut olacak şekilde düzenle\n",
    "    indices_tensor = torch.LongTensor(all_indices)\n",
    "    labels_tensor = torch.FloatTensor(labels).unsqueeze(1) # BCEWithLogitsLoss için (batch_size, 1) şekli uygun olabilir\n",
    "\n",
    "    return indices_tensor, labels_tensor\n",
    "\n",
    "# Kelime haznesini oluştur\n",
    "word_to_idx, idx_to_word = build_vocab(train_data)\n",
    "vocab_size = len(word_to_idx)\n",
    "print(f\"Kelime Haznesi Boyutu: {vocab_size}\")\n",
    "\n",
    "# Maksimum cümle uzunluğunu belirle (padding için)\n",
    "max_sequence_length = max(len(clean_and_tokenize(s)) for s in train_data.keys())\n",
    "print(f\"Maksimum Dizi Uzunluğu: {max_sequence_length}\")\n",
    "\n",
    "# Veri setlerini tensorlara dönüştür\n",
    "train_indices_tensor, train_labels_tensor = prepare_dataset(train_data, word_to_idx, max_sequence_length)\n",
    "test_indices_tensor, test_labels_tensor = prepare_dataset(test_data, word_to_idx, max_sequence_length)\n",
    "\n",
    "print(f\"Eğitim Verisi Tensor Şekli: {train_indices_tensor.shape}, Etiket Şekli: {train_labels_tensor.shape}\")\n",
    "print(f\"Test Verisi Tensor Şekli: {test_indices_tensor.shape}, Etiket Şekli: {test_labels_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9628a458-907c-4c3e-8cb7-0ee857b96ece",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75165840-ed8d-436f-98f7-87316a9e9c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Mimarisi:\n",
      "SentimentRNN(\n",
      "  (embedding): Embedding(20, 32)\n",
      "  (rnn): RNN(32, 32, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # batch_first=True: Giriş tensorunun şekli (batch, sequence, feature) olur\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size) # Tam bağlı katman (Fully Connected)\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text girdisi (batch_size, sequence_length) şeklinde indeks tensoru\n",
    "        embedded = self.embedding(text) # Çıktı şekli: (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "        # RNN katmanı\n",
    "        # output: Tüm zaman adımlarının gizli durumları (batch_size, sequence_length, hidden_size)\n",
    "        # hidden: Son zaman adımının gizli durumu (1, batch_size, hidden_size) - SimpleRNN için\n",
    "        output, hidden = self.rnn(embedded)\n",
    "\n",
    "        # Sınıflandırma için son zaman adımının gizli durumunu kullan\n",
    "        # hidden[:, -1, :] -> (batch_size, hidden_size) şeklini alır\n",
    "        # SimpleRNN'de 'hidden' tensoru (num_layers * num_directions, batch_size, hidden_size) şeklindedir.\n",
    "        # Bizde num_layers=1, num_directions=1. Yani hidden[0] son gizli durumdur.\n",
    "        final_hidden_state = hidden[0] # Şekil: (batch_size, hidden_size)\n",
    "\n",
    "        # Tam bağlı katmana besle\n",
    "        logits = self.fc(final_hidden_state) # Çıktı şekli: (batch_size, output_size)\n",
    "\n",
    "        return logits\n",
    "\n",
    "print(\"\\nModel Mimarisi:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f77851-c652-4612-b126-a44c639e8d26",
   "metadata": {},
   "source": [
    "## EĞİTİM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e10f446-8dc5-43ff-8485-34dcd6a2deba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model başarıyla yeniden başlatıldı.\n",
      "Kayıp fonksiyonu ve Optimizer yeniden başlatıldı.\n",
      "\n",
      "Eğitim Başlıyor...\n",
      "Epoch 1/500 | Eğitim Kaybı: 0.7137, Eğitim Doğruluğu: 0.4483 | Test Kaybı: 0.6974, Test Doğruluğu: 0.5000\n",
      "Epoch 100/500 | Eğitim Kaybı: 0.3476, Eğitim Doğruluğu: 0.8621 | Test Kaybı: 0.2870, Test Doğruluğu: 0.9000\n",
      "Epoch 200/500 | Eğitim Kaybı: 0.0028, Eğitim Doğruluğu: 1.0000 | Test Kaybı: 0.0027, Test Doğruluğu: 1.0000\n",
      "Epoch 300/500 | Eğitim Kaybı: 0.0007, Eğitim Doğruluğu: 1.0000 | Test Kaybı: 0.0007, Test Doğruluğu: 1.0000\n",
      "Epoch 400/500 | Eğitim Kaybı: 0.0003, Eğitim Doğruluğu: 1.0000 | Test Kaybı: 0.0003, Test Doğruluğu: 1.0000\n",
      "Epoch 500/500 | Eğitim Kaybı: 0.0002, Eğitim Doğruluğu: 1.0000 | Test Kaybı: 0.0002, Test Doğruluğu: 1.0000\n",
      "Eğitim Tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "# Bu hücre, Jupyter Notebook'unuzda eğitimi başlattığınız hücre olacak.\n",
    "# Bu hücreyi her çalıştırdığınızda model baştan başlatılacaktır.\n",
    "\n",
    "# Model Hiperparametreleri (Bu hücrede tanımlanabilir veya önceki hücrelerden alınabilir)\n",
    "embedding_dim = 32\n",
    "hidden_size = 32\n",
    "output_size = 1 # Binary classification\n",
    "\n",
    "# Eğitim Hiperparametreleri (Bu hücrede tanımlanabilir)\n",
    "epochs = 500\n",
    "batch_size = 8\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Modeli Yeniden Başlat (Her hücre çalıştırıldığında yeni bir instance oluşturulur)\n",
    "# Bu adım, modelin ağırlıklarının her zaman rastgele başlangıç değerleriyle başlamasını sağlar.\n",
    "model = SentimentRNN(vocab_size, embedding_dim, hidden_size, output_size).to(device)\n",
    "print(\"Model başarıyla yeniden başlatıldı.\")\n",
    "\n",
    "# Kayıp Fonksiyonu ve Optimizer'ı Yeniden Başlat\n",
    "# Optimizer, model parametrelerine bağlı olduğu için modelle birlikte yeniden başlatılmalıdır.\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(\"Kayıp fonksiyonu ve Optimizer yeniden başlatıldı.\")\n",
    "\n",
    "# Veri Yükleyicilerini Yeniden Oluştur (Batch boyutu veya shuffle değişirse)\n",
    "# Eğer batch_size bu hücrede tanımlandıysa, DataLoader'ları burada oluşturmak mantıklı.\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Dikkat: train_indices_tensor ve train_labels_tensor'ın önceki hücrelerde oluşturulduğunu varsayıyoruz.\n",
    "train_dataset = TensorDataset(train_indices_tensor, train_labels_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Dikkat: test_indices_tensor ve test_labels_tensor'ın önceki hücrelerde oluşturulduğunu varsayıyoruz.\n",
    "test_dataset = TensorDataset(test_indices_tensor, test_labels_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "print(\"\\nEğitim Başlıyor...\")\n",
    "# Eğitim döngüsü\n",
    "for epoch in range(epochs):\n",
    "    model.train() # Modeli eğitim moduna al\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_examples = 0\n",
    "\n",
    "    for batch_indices, batch_labels in train_loader:\n",
    "        batch_indices, batch_labels = batch_indices.to(device), batch_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_indices)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * batch_indices.size(0)\n",
    "        total_examples += batch_indices.size(0)\n",
    "        predicted_labels = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        correct_predictions += (predicted_labels == batch_labels).sum().item()\n",
    "\n",
    "    avg_train_loss = total_loss / total_examples\n",
    "    train_accuracy = correct_predictions / total_examples\n",
    "\n",
    "    # Test (Doğrulama) Seti Üzerinde Değerlendirme\n",
    "    model.eval() # Modeli değerlendirme moduna al\n",
    "    total_test_loss = 0\n",
    "    correct_test_predictions = 0\n",
    "    total_test_examples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_batch_indices, test_batch_labels in test_loader:\n",
    "            test_batch_indices, test_batch_labels = test_batch_indices.to(device), test_batch_labels.to(device)\n",
    "            test_outputs = model(test_batch_indices)\n",
    "            test_loss = criterion(test_outputs, test_batch_labels)\n",
    "\n",
    "            total_test_loss += test_loss.item() * test_batch_indices.size(0)\n",
    "            total_test_examples += test_batch_indices.size(0)\n",
    "\n",
    "            predicted_test_labels = (torch.sigmoid(test_outputs) > 0.5).float()\n",
    "            correct_test_predictions += (predicted_test_labels == test_batch_labels).sum().item()\n",
    "\n",
    "    avg_test_loss = total_test_loss / total_test_examples\n",
    "    test_accuracy = correct_test_predictions / total_test_examples\n",
    "\n",
    "    if (epoch + 1) % 100 == 0 or epoch == 0: # Daha az çıktı almak için 100 epokta bir yazdır\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Eğitim Kaybı: {avg_train_loss:.4f}, Eğitim Doğruluğu: {train_accuracy:.4f} | \"\n",
    "              f\"Test Kaybı: {avg_test_loss:.4f}, Test Doğruluğu: {test_accuracy:.4f}\")\n",
    "\n",
    "print(\"Eğitim Tamamlandı.\")\n",
    "\n",
    "# Eğitim sonrası test verisi üzerinde nihai değerlendirme veya tahminler\n",
    "# ... (İsteğe bağlı, önceki koddan alabilirsiniz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a429f83-1b6f-424e-b1df-c2b21621a1fb",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d60c424b-8202-4936-9ab0-69adee58c20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test verisi üzerinde nihai tahminler:\n",
      "Cümle: 'this is happy'\n",
      "  Tahmini Olasılık: 0.9999\n",
      "  Tahmin Edilen Etiket: Pozitif (Gerçek: Pozitif)\n",
      "Cümle: 'i am good'\n",
      "  Tahmini Olasılık: 0.9999\n",
      "  Tahmin Edilen Etiket: Pozitif (Gerçek: Pozitif)\n",
      "Cümle: 'this is not happy'\n",
      "  Tahmini Olasılık: 0.0002\n",
      "  Tahmin Edilen Etiket: Negatif (Gerçek: Negatif)\n",
      "Cümle: 'i am not good'\n",
      "  Tahmini Olasılık: 0.0002\n",
      "  Tahmin Edilen Etiket: Negatif (Gerçek: Negatif)\n",
      "Cümle: 'this is not bad'\n",
      "  Tahmini Olasılık: 0.9999\n",
      "  Tahmin Edilen Etiket: Pozitif (Gerçek: Pozitif)\n",
      "Cümle: 'i am not sad'\n",
      "  Tahmini Olasılık: 0.9999\n",
      "  Tahmin Edilen Etiket: Pozitif (Gerçek: Pozitif)\n",
      "Cümle: 'i am very good'\n",
      "  Tahmini Olasılık: 0.9999\n",
      "  Tahmin Edilen Etiket: Pozitif (Gerçek: Pozitif)\n",
      "Cümle: 'this is very bad'\n",
      "  Tahmini Olasılık: 0.0002\n",
      "  Tahmin Edilen Etiket: Negatif (Gerçek: Negatif)\n",
      "Cümle: 'i am very sad'\n",
      "  Tahmini Olasılık: 0.0002\n",
      "  Tahmin Edilen Etiket: Negatif (Gerçek: Negatif)\n",
      "Cümle: 'this is bad not good'\n",
      "  Tahmini Olasılık: 0.0002\n",
      "  Tahmin Edilen Etiket: Negatif (Gerçek: Negatif)\n",
      "Cümle: 'this is good and happy'\n",
      "  Tahmini Olasılık: 0.9999\n",
      "  Tahmin Edilen Etiket: Pozitif (Gerçek: Pozitif)\n",
      "Cümle: 'i am not good and not happy'\n",
      "  Tahmini Olasılık: 0.0002\n",
      "  Tahmin Edilen Etiket: Negatif (Gerçek: Negatif)\n",
      "Cümle: 'i am not at all sad'\n",
      "  Tahmini Olasılık: 0.9999\n",
      "  Tahmin Edilen Etiket: Pozitif (Gerçek: Pozitif)\n",
      "Cümle: 'this is not at all good'\n",
      "  Tahmini Olasılık: 0.0002\n",
      "  Tahmin Edilen Etiket: Negatif (Gerçek: Negatif)\n",
      "Cümle: 'this is not at all bad'\n",
      "  Tahmini Olasılık: 0.9999\n",
      "  Tahmin Edilen Etiket: Pozitif (Gerçek: Pozitif)\n",
      "Cümle: 'this is good right now'\n",
      "  Tahmini Olasılık: 0.9998\n",
      "  Tahmin Edilen Etiket: Pozitif (Gerçek: Pozitif)\n",
      "Cümle: 'this is sad right now'\n",
      "  Tahmini Olasılık: 0.0002\n",
      "  Tahmin Edilen Etiket: Negatif (Gerçek: Negatif)\n",
      "Cümle: 'this is very bad right now'\n",
      "  Tahmini Olasılık: 0.0002\n",
      "  Tahmin Edilen Etiket: Negatif (Gerçek: Negatif)\n",
      "Cümle: 'this was good earlier'\n",
      "  Tahmini Olasılık: 0.9999\n",
      "  Tahmin Edilen Etiket: Pozitif (Gerçek: Pozitif)\n",
      "Cümle: 'i was not happy and not good earlier'\n",
      "  Tahmini Olasılık: 0.0002\n",
      "  Tahmin Edilen Etiket: Negatif (Gerçek: Negatif)\n",
      "\n",
      "Nihai Test Doğruluğu: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest verisi üzerinde nihai tahminler:\")\n",
    "model.eval() # Modeli değerlendirme moduna al\n",
    "correct_final_test_predictions = 0\n",
    "\n",
    "with torch.no_grad(): # Gradyan hesaplamayı kapat\n",
    "    for sentence, true_label in test_data.items():\n",
    "        # Tek bir cümle için tahmin yapmak için tensoru hazırla\n",
    "        indices = sentence_to_indices(sentence, word_to_idx, max_sequence_length)\n",
    "        input_tensor = torch.LongTensor([indices]).to(device) # Batch boyutu 1 olan tensor\n",
    "\n",
    "        output = model(input_tensor)\n",
    "        predicted_prob = torch.sigmoid(output).item() # Logit'ten olasılığa (.item() ile PyTorch tensorundan Python sayısına)\n",
    "        predicted_label = predicted_prob > 0.5\n",
    "        true_label_bool = bool(true_label) # Boolean olarak al\n",
    "\n",
    "        print(f\"Cümle: '{sentence}'\")\n",
    "        print(f\"  Tahmini Olasılık: {predicted_prob:.4f}\")\n",
    "        print(f\"  Tahmin Edilen Etiket: {'Pozitif' if predicted_label else 'Negatif'} (Gerçek: {'Pozitif' if true_label_bool else 'Negatif'})\")\n",
    "\n",
    "        if predicted_label == true_label_bool:\n",
    "            correct_final_test_predictions += 1\n",
    "\n",
    "final_test_accuracy = correct_final_test_predictions / len(test_data)\n",
    "print(f\"\\nNihai Test Doğruluğu: {final_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546d4d2-c8e7-4230-8b62-ff9ca5f4620d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
